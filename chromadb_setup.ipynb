{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43d2babc",
   "metadata": {},
   "source": [
    "ChromaDB Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2a598a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "if not os.environ.get(\"GROQ_API_KEY\"):\n",
    "    raise RuntimeError(\"GROQ_API_KEY not found in environment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd00241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "chroma_settings = Settings(persist_directory=\"./chroma_db\")\n",
    "client = chromadb.Client(settings=chroma_settings)\n",
    "collection = client.get_or_create_collection(name=\"food_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bbe88d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18046/3186043211.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedder = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "/home/chahar/miniconda3/envs/food/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Generate embeddings using HuggingFace\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embedder = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627d7e57",
   "metadata": {},
   "source": [
    "sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dc8e2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    \"Apple: 95 kcal, 0.3 g fat, 0.5 g protein\",\n",
    "    \"Banana: 105 kcal, 0.4 g fat, 1.3 g protein\"\n",
    "]\n",
    "metas = [{\"food\": \"apple\"}, {\"food\": \"banana\"}]\n",
    "ids = [\"apple_1\", \"banana_1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c094a714",
   "metadata": {},
   "source": [
    "adding to chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "615ea7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = embedder.embed_documents(docs)\n",
    "collection.add(\n",
    "    documents=docs,\n",
    "    embeddings=embs,\n",
    "    metadatas=metas,\n",
    "    ids=ids,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f446895f",
   "metadata": {},
   "source": [
    "using langchain to connect chroma vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bd437a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18046/3542922873.py:3: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = LCChroma(\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma as LCChroma\n",
    "\n",
    "vectorstore = LCChroma(\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    collection_name=\"food_info\",\n",
    "    embedding_function=embedder,\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f694e8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import init_chat_model\n",
    "llm = init_chat_model(\n",
    "    model=\"llama3-8b-8192\", \n",
    "    model_provider=\"groq\",\n",
    "    temperature=0.2,\n",
    "    max_tokens=256\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076b3647",
   "metadata": {},
   "source": [
    "creating retrievalQA chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4c14e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "custom_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Use only the following context to answer the question as briefly and factually as possible.\n",
    "If the answer is numerical or specific, quote it exactly.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",  # default, but explicit\n",
    "    chain_type_kwargs={\"prompt\": custom_prompt}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57c5c18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§  Answer: According to the United States Department of Agriculture (USDA), one medium-sized banana (approximately 100g) contains 105 calories (kcal).\n"
     ]
    }
   ],
   "source": [
    "query = \"How many kcal are there in bananas?\"\n",
    "answer = qa_chain.run(query)\n",
    "print(\"ðŸ§  Answer:\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ce14bd",
   "metadata": {},
   "source": [
    "## Creating vector embeddings of our 101 food images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c54bce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chahar/miniconda3/envs/food/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import os\n",
    "\n",
    "# Load the dataset\n",
    "data_path = \"data/food_macros_100_realnames.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Load CLIP text encoder model (ViT-B/32 text projection part)\n",
    "model = SentenceTransformer(\"clip-ViT-B-32\")\n",
    "\n",
    "# Initialize ChromaDB client\n",
    "client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "collection = client.get_or_create_collection(name=\"food_macros_clip\")\n",
    "\n",
    "# Create embeddings and store in ChromaDB\n",
    "for i, row in df.iterrows():\n",
    "    food_description = f\"{row['Food']} with {row['Protein (g)']}g protein, {row['Carbs (g)']}g carbs, {row['Fat (g)']}g fat and {row['Calories']} calories\"\n",
    "    embedding = model.encode(food_description).tolist()\n",
    "\n",
    "    collection.add(\n",
    "        ids=[f\"food_{i}\"],\n",
    "        documents=[food_description],\n",
    "        metadatas=[{\n",
    "            \"food\": row['Food'],\n",
    "            \"calories\": row['Calories'],\n",
    "            \"protein\": row['Protein (g)'],\n",
    "            \"carbs\": row['Carbs (g)'],\n",
    "            \"fat\": row['Fat (g)']\n",
    "        }],\n",
    "        embeddings=[embedding]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dbf629a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "food",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
